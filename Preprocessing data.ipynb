{
 "cells": [
  {
   "cell_type": "raw",
   "id": "881e3537-d6ea-4a53-adbf-2a819d6f7c1f",
   "metadata": {},
   "source": [
    "                                                                                Captions Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4da9ab3e-f41f-49ca-a50a-0bfd74dcdb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 15:30:34.243144: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-01 15:30:34.274515: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748772034.296099   43036 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748772034.301880   43036 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748772034.326527   43036 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748772034.326558   43036 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748772034.326560   43036 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748772034.326561   43036 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-01 15:30:34.336405: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1098568a-0a57-4e82-b6b6-d97b8b3594b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_disk(path):\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        loaded_list = pickle.load(f)\n",
    "\n",
    "    return loaded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d091d7b-7bfd-440a-8f28-f6b912881233",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=load_from_disk('./Vocabulary/vocab.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a7732b6-e549-49e9-8403-fea7e20567e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400002\n",
      "['<SOS>', '<EOS>', '!', '!!', '!!!', '!!!!', '!!!!!', '!?', '!?!', '\"']\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))\n",
    "print(vocab[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13084905-4711-41e2-8e7f-f8da4310d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = TextVectorization(\n",
    "    standardize=None,\n",
    "    output_mode='int',\n",
    "    vocabulary=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e66aca3-3735-4d0a-8754-8121fdcbc35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400004\n",
      "['', '[UNK]', '<SOS>', '<EOS>', '!', '!!', '!!!', '!!!!', '!!!!!', '!?']\n"
     ]
    }
   ],
   "source": [
    "vector_vocab=vectorize_layer.get_vocabulary()\n",
    "print(len(vector_vocab))\n",
    "print(vector_vocab[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c324f1a9-8f3e-4547-8b35-3b67ed89a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_captions=load_from_disk('./Data/train_captions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee719ece-1f11-4d38-a746-e42c51d8e57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28320\n",
      "['A child in a pink dress is climbing up a set of stairs in an entry way .', 'A girl going into a wooden building .', 'A little girl climbing into a wooden playhouse .', 'A little girl climbing the stairs to her playhouse .', 'A little girl in a pink dress going into a wooden cabin .', 'A black dog and a spotted dog are fighting', 'A black dog and a tri-colored dog playing with each other on the road .', 'A black dog and a white dog with brown spots are staring at each other in the street .', 'Two dogs of different breeds looking at each other on the road .', 'Two dogs on pavement moving toward each other .']\n"
     ]
    }
   ],
   "source": [
    "print(len(train_captions))\n",
    "print(train_captions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea281581-3a73-445c-96ea-d778c666de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Step 1: Convert all characters to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Step 2: Remove punctuation\n",
    "    # str.maketrans('', '', string.punctuation) creates a translation table\n",
    "    # str.translate(...) removes all punctuation characters in that table\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    text=\"<SOS> \"+text+\" <EOS>\"\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d7852c0-e97c-4e2c-ae80-9f2bf14333de",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_captions=[]\n",
    "for sentence in train_captions:\n",
    "    sen=preprocess_text(sentence)\n",
    "    processed_train_captions.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27c6a9a6-06db-4daf-85cb-57b87a16adac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28320\n",
      "['<SOS> a child in a pink dress is climbing up a set of stairs in an entry way  <EOS>', '<SOS> a girl going into a wooden building  <EOS>', '<SOS> a little girl climbing into a wooden playhouse  <EOS>', '<SOS> a little girl climbing the stairs to her playhouse  <EOS>', '<SOS> a little girl in a pink dress going into a wooden cabin  <EOS>', '<SOS> a black dog and a spotted dog are fighting <EOS>', '<SOS> a black dog and a tricolored dog playing with each other on the road  <EOS>', '<SOS> a black dog and a white dog with brown spots are staring at each other in the street  <EOS>', '<SOS> two dogs of different breeds looking at each other on the road  <EOS>', '<SOS> two dogs on pavement moving toward each other  <EOS>']\n"
     ]
    }
   ],
   "source": [
    "print(len(processed_train_captions))\n",
    "print(processed_train_captions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0a58219-ab4a-4710-96fb-70344f3fa334",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_captions=vectorize_layer(processed_train_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab983c56-102b-47d7-bb53-cc8b3e39663b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(processed_captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3cc1f16-e6df-4708-89e6-64f51aa05b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([28320, 38])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_captions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9fd3edb-5365-4ad2-a825-542ec1adecc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 38), dtype=int64, numpy=\n",
       "array([[     2,  43013,  98973, 188484,  43013, 285071, 129288, 192976,\n",
       "        102812, 373320,  43013, 325902, 268049, 341258, 188484,  54276,\n",
       "        138044, 384125,      3,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0],\n",
       "       [     2,  43013, 161847, 163748, 191814,  43013, 389565,  86374,\n",
       "             3,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0],\n",
       "       [     2,  43013, 223833, 161847, 102812, 191814,  43013, 389565,\n",
       "        286442,      3,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0],\n",
       "       [     2,  43013, 223833, 161847, 102812, 357269, 341258, 360918,\n",
       "        177106, 286442,      3,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0],\n",
       "       [     2,  43013, 223833, 161847, 188484,  43013, 285071, 129288,\n",
       "        163748, 191814,  43013, 389565,  88907,      3,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0]])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_captions[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac16fed8-8d81-4ccd-bf94-8600461d8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_captions_np=processed_captions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b09e8b30-bc10-42bd-bd77-0ca4406f3c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(processed_captions_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "495ef7f6-37e0-4e59-80b8-2fdd128444d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28320, 38)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_captions_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b11e9b27-fccd-408d-8d5e-ecb7b1eb31c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     2,  43013,  98973, 188484,  43013, 285071, 129288, 192976,\n",
       "        102812, 373320,  43013, 325902, 268049, 341258, 188484,  54276,\n",
       "        138044, 384125,      3,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0],\n",
       "       [     2,  43013, 161847, 163748, 191814,  43013, 389565,  86374,\n",
       "             3,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0],\n",
       "       [     2,  43013, 223833, 161847, 102812, 191814,  43013, 389565,\n",
       "        286442,      3,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0],\n",
       "       [     2,  43013, 223833, 161847, 102812, 357269, 341258, 360918,\n",
       "        177106, 286442,      3,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0],\n",
       "       [     2,  43013, 223833, 161847, 188484,  43013, 285071, 129288,\n",
       "        163748, 191814,  43013, 389565,  88907,      3,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_captions_np[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e2fc0-edf9-4da1-87dc-cf2a4ed48b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./Data/processed_train_captions.npy',processed_captions_np)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f131ae0a-d44a-4f22-8c6e-9c18a907ddb9",
   "metadata": {},
   "source": [
    "                                                                                    Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffc6f6b-4235-4b2e-939c-60004f7cfd4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
