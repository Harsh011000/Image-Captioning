{
 "cells": [
  {
   "cell_type": "raw",
   "id": "881e3537-d6ea-4a53-adbf-2a819d6f7c1f",
   "metadata": {},
   "source": [
    "                                                                                Captions Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4da9ab3e-f41f-49ca-a50a-0bfd74dcdb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 19:06:42.036324: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-05 19:06:42.068367: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749130602.101580   12188 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749130602.112932   12188 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749130602.144517   12188 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749130602.144557   12188 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749130602.144581   12188 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749130602.144586   12188 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-05 19:06:42.152746: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras.layers import TextVectorization\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1098568a-0a57-4e82-b6b6-d97b8b3594b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_disk(path):\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        loaded_list = pickle.load(f)\n",
    "\n",
    "    return loaded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d091d7b-7bfd-440a-8f28-f6b912881233",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=load_from_disk('./Vocabulary/new_vocab.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a7732b6-e549-49e9-8403-fea7e20567e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7826\n",
      "['<SOS>', '<EOS>', '08', '1', '10', '104', '11', '12', '13', '157']\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))\n",
    "print(vocab[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13084905-4711-41e2-8e7f-f8da4310d914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1749130617.154223   12188 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# vectorize_layer = TextVectorization(\n",
    "#     standardize=None,\n",
    "#     split=None,\n",
    "#     output_mode='int',\n",
    "#     vocabulary=vocab)\n",
    "\n",
    "vectorize_layer=tf.keras.layers.StringLookup(mask_token='',vocabulary=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e66aca3-3735-4d0a-8754-8121fdcbc35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7828\n",
      "['', '[UNK]', '<SOS>', '<EOS>', '08', '1', '10', '104', '11', '12']\n"
     ]
    }
   ],
   "source": [
    "vector_vocab=vectorize_layer.get_vocabulary()\n",
    "print(len(vector_vocab))\n",
    "print(vector_vocab[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c324f1a9-8f3e-4547-8b35-3b67ed89a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_captions=load_from_disk('./Data/train_captions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee719ece-1f11-4d38-a746-e42c51d8e57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28320\n",
      "['A child in a pink dress is climbing up a set of stairs in an entry way .', 'A girl going into a wooden building .', 'A little girl climbing into a wooden playhouse .', 'A little girl climbing the stairs to her playhouse .', 'A little girl in a pink dress going into a wooden cabin .', 'A black dog and a spotted dog are fighting', 'A black dog and a tri-colored dog playing with each other on the road .', 'A black dog and a white dog with brown spots are staring at each other in the street .', 'Two dogs of different breeds looking at each other on the road .', 'Two dogs on pavement moving toward each other .']\n"
     ]
    }
   ],
   "source": [
    "print(len(dev_captions))\n",
    "print(dev_captions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea281581-3a73-445c-96ea-d778c666de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Step 1: Convert all characters to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Step 2: Remove punctuation\n",
    "    # str.maketrans('', '', string.punctuation) creates a translation table\n",
    "    # str.translate(...) removes all punctuation characters in that table\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    text=\"<SOS> \"+text+\" <EOS>\"\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d7852c0-e97c-4e2c-ae80-9f2bf14333de",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dev_captions=[]\n",
    "for sentence in dev_captions:\n",
    "    sen=preprocess_text(sentence)\n",
    "    processed_dev_captions.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27c6a9a6-06db-4daf-85cb-57b87a16adac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28320\n",
      "['<SOS> a child in a pink dress is climbing up a set of stairs in an entry way  <EOS>', '<SOS> a girl going into a wooden building  <EOS>', '<SOS> a little girl climbing into a wooden playhouse  <EOS>', '<SOS> a little girl climbing the stairs to her playhouse  <EOS>', '<SOS> a little girl in a pink dress going into a wooden cabin  <EOS>', '<SOS> a black dog and a spotted dog are fighting <EOS>', '<SOS> a black dog and a tricolored dog playing with each other on the road  <EOS>', '<SOS> a black dog and a white dog with brown spots are staring at each other in the street  <EOS>', '<SOS> two dogs of different breeds looking at each other on the road  <EOS>', '<SOS> two dogs on pavement moving toward each other  <EOS>']\n"
     ]
    }
   ],
   "source": [
    "print(len(processed_dev_captions))\n",
    "print(processed_dev_captions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "219a5a47-42b2-4dd0-ae1f-6b9ecc010d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "split_processed_dev_captions=[]\n",
    "for x in processed_dev_captions:\n",
    "    split=x.split()\n",
    "    split_processed_dev_captions.append(split)\n",
    "print('completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b024851e-3052-4946-9200-0154b225a3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28320"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_processed_dev_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d511a85-9576-4100-8922-9f82b44eea34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<SOS>',\n",
       " 'a',\n",
       " 'child',\n",
       " 'in',\n",
       " 'a',\n",
       " 'pink',\n",
       " 'dress',\n",
       " 'is',\n",
       " 'climbing',\n",
       " 'up',\n",
       " 'a',\n",
       " 'set',\n",
       " 'of',\n",
       " 'stairs',\n",
       " 'in',\n",
       " 'an',\n",
       " 'entry',\n",
       " 'way',\n",
       " '<EOS>']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_processed_dev_captions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "653a9b45-0ec6-4313-a21d-9d0d67e9ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_input_captions=[]\n",
    "dev_label_captions=[]\n",
    "for x in split_processed_dev_captions:\n",
    "    dev_input_captions.append(x[0:-1])\n",
    "    dev_label_captions.append(x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1748773-2638-4c58-8392-ada9ea582b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<SOS>',\n",
       "  'a',\n",
       "  'child',\n",
       "  'in',\n",
       "  'a',\n",
       "  'pink',\n",
       "  'dress',\n",
       "  'is',\n",
       "  'climbing',\n",
       "  'up',\n",
       "  'a',\n",
       "  'set',\n",
       "  'of',\n",
       "  'stairs',\n",
       "  'in',\n",
       "  'an',\n",
       "  'entry',\n",
       "  'way'],\n",
       " ['<SOS>', 'a', 'girl', 'going', 'into', 'a', 'wooden', 'building']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_input_captions[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0a58219-ab4a-4710-96fb-70344f3fa334",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_dev_input_captions=vectorize_layer(tf.ragged.constant(dev_input_captions, dtype=tf.string))\n",
    "processed_dev_label_captions=vectorize_layer(tf.ragged.constant(dev_label_captions,dtype=tf.string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab983c56-102b-47d7-bb53-cc8b3e39663b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(processed_dev_input_captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ebf6cf0-d9b7-4020-bc86-e7215d949821",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dev_input_captions=processed_dev_input_captions.to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59f1018d-99de-402a-a151-cf00ea063639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([28320, 37])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dev_input_captions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57964e9e-111f-4f7e-a837-75d626059fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dev_label_captions=processed_dev_label_captions.to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "355fc5ff-73b2-48bd-818a-d1be9de6efbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([28320, 37])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dev_label_captions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1963f27-6809-447b-bef2-1f0606526979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(37,), dtype=int64, numpy=\n",
       "array([   2,   51, 1301, 3457,   51, 4957, 2121, 3541, 1398, 7352,   51,\n",
       "       5892, 4519, 6504, 3457,  218, 2332, 7565,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dev_input_captions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4aa857c-c305-489a-bc8c-e6ed8c4bafc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(37,), dtype=int64, numpy=\n",
       "array([  51, 1301, 3457,   51, 4957, 2121, 3541, 1398, 7352,   51, 5892,\n",
       "       4519, 6504, 3457,  218, 2332, 7565,    3,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dev_label_captions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac16fed8-8d81-4ccd-bf94-8600461d8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dev_input_captions_np=processed_dev_input_captions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b09e8b30-bc10-42bd-bd77-0ca4406f3c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(processed_dev_input_captions_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "495ef7f6-37e0-4e59-80b8-2fdd128444d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28320, 37)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dev_input_captions_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f772e275-d863-4abe-a277-179de306159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dev_label_captions_np=processed_dev_label_captions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65d946eb-f85d-429b-ba0a-f45fc9b146af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(processed_dev_label_captions_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1a59d71-3740-47fd-924b-f371cd105dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28320, 37)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dev_label_captions_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e6e2fc0-edf9-4da1-87dc-cf2a4ed48b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./Data/processed_train_input_captions.npy',processed_dev_input_captions_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75d0d980-9690-413e-b091-3767b8a7938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./Data/processed_train_label_captions.npy',processed_dev_label_captions_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
